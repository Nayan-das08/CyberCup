{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2362285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shivansh uppal\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tflearn # tensorflow deep learning\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import nltk # natural langauge tool kit for nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a2d74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\shivansh\n",
      "[nltk_data]     uppal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c852d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\programming languages\\CYBERCUP\\CyberCup\\manya\\data.json', 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e59df18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire</td>\n",
       "      <td>[I am stuck in fire, Fire Fire Fire, Flames al...</td>\n",
       "      <td>[Please consider the following measures- \\n 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earthquake</td>\n",
       "      <td>[I am in an earthquake, objects are falling, g...</td>\n",
       "      <td>[Please consider the following measures- \\n 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flood</td>\n",
       "      <td>[Lots of water around me, neighbourhood is flo...</td>\n",
       "      <td>[Please consider the following measures- \\n 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0        Fire  [I am stuck in fire, Fire Fire Fire, Flames al...   \n",
       "1  Earthquake  [I am in an earthquake, objects are falling, g...   \n",
       "2       Flood  [Lots of water around me, neighbourhood is flo...   \n",
       "\n",
       "                                           responses  \n",
       "0  [Please consider the following measures- \\n 1....  \n",
       "1  [Please consider the following measures- \\n 1....  \n",
       "2  [Please consider the following measures- \\n 1....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting dictinary to pandas dataframe\n",
    "df = pd.DataFrame.from_dict(dataset['data'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42a8f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", ',', '[', ']', 'a', 'al', 'alarm', 'alert', 'am', 'an', 'and', 'ar', 'around', 'at', 'auth', 'bed', 'been', 'brigad', 'build', 'burn', 'cal', 'can', 'car', 'caught', 'chief', 'chok', 'clos', 'contact', 'crack', 'dam', 'depart', 'develop', 'district', 'door', 'dril', 'drown', 'earthquak', 'emerg', 'engin', 'escap', 'everyth', 'everywh', 'exit', 'explod', 'extinct', 'fal', 'fast', 'fil', 'fir', 'firefight', 'firem', 'flam', 'flood', 'for', 'from', 'ground', 'has', 'hav', 'hazard', 'heavy', 'help', 'her', 'high', 'hom', 'hous', 'hydr', 'i', 'immedy', 'in', 'into', 'is', 'it', 'lan', 'let', 'light', 'lot', 'me', 'mov', 'my', 'nee', 'neighbo', 'next', 'not', 'object', 'of', 'op', 'outsid', 'patrol', 'pay', 'peopl', 'phon', 'pleas', 'protect', 'rainfal', 'reach', 'rescu', 'road', 'room', 'rupt', 'serv', 'shak', 'smok', 'spread', 'standstil', 'stat', 'stop', 'stuck', 'submerg', 'surround', 'swing', 'the', 'to', 'trig', 'und', 'unstop', 'urg', 'us', 'very', 'volunt', 'wat', 'we', 'with', 'work']\n"
     ]
    }
   ],
   "source": [
    "#prepare training data\n",
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []\n",
    "\n",
    "for data in dataset[\"data\"]: # dataset is dict. 'data' is key. dataset['data'] is array of dict. data is dict\n",
    "    for pattern in data[\"patterns\"]: #pattern is array element in dict element of array of dict\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        docs_x.append(w)\n",
    "        docs_y.append(data[\"tag\"])\n",
    "\n",
    "    if data[\"tag\"] not in labels:\n",
    "        labels.append(data[\"tag\"])\n",
    "\n",
    "ignore_words = ['?', '.', '!']\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72fe350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455f0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Earthquake', 'Fire', 'Flood']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d3eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am', 'stuck', 'in', 'fire'], ['Fire', 'Fire', 'Fire'], ['Flames', 'all', 'around', 'me'], ['Fire', 'all', 'around', 'me'], ['Fire', 'surrounds', 'me'], ['Fire', 'in', 'building'], ['i', 'am', 'caught', 'in', 'fire'], ['Burning', 'my', 'house'], ['high', 'flames', 'burning', 'my', 'car'], ['Smoke', 'is', 'choking', 'me'], ['It', \"'s\", 'urgent', 'I', 'need', 'to', 'call', 'the', '[', 'fire', 'department', ']', ',', 'please'], ['We', 'need', 'the', '[', 'fire', 'brigade', ']', ',', 'please'], ['I', 'have', 'to', 'call', 'the', '[', 'firefighters', ']', ',', 'please'], ['A', 'fire', 'has', 'spread', 'in', 'the', 'room', ',', 'I', 'have', 'to', 'call', 'the', '[', 'firefighters', ']', ',', 'it', \"'s\", 'urgent', '!', '!', '!'], ['The', 'fire', 'alarm', 'has', 'been', 'triggered', ',', 'we', 'need', 'to', 'contact', 'the', '[', 'fire', 'department', ']', ',', 'we', 'need', 'an', 'help', '!', '!', '!'], ['I', 'have', 'to', 'call', 'the', '[', 'fire', 'chief', ']', ',', 'please'], ['I', 'need', 'to', 'alert', 'the', '[', 'firefighters', ']', ',', 'fire', 'doors', 'are', 'open'], ['I', 'need', 'to', 'call', '[', 'firefighters', ']', ',', 'fire', 'has', 'spread', 'into', 'the', 'building', ',', 'is', 'not', 'a', 'fire', 'drill'], ['I', 'have', 'to', 'call', 'the', '[', 'fire', 'engine', ']', ',', 'please'], ['Fire', 'is', 'spread', 'into', 'the', 'rooms', ',', 'we', 'need', 'a', 'fire', 'escape', 'to', 'exit', 'from', 'the', 'building', ',', 'I', 'need', 'to', 'reach', 'the', '[', 'fire', 'department', ']', '!', '!', '!'], ['I', 'have', 'to', 'call', '[', 'firefighters', ']', 'and', 'use', 'fire', 'exit', '!', '!', '!'], ['We', 'need', 'a', 'fire', 'extinguisher', 'to', 'stop', 'the', 'fire', ',', 'I', 'need', 'to', 'call', 'the', '[', 'fire', 'department', ']', ',', 'please'], ['Pay', 'attention', 'to', 'the', 'fire', 'hazard', ',', 'I', 'have', 'to', 'call', 'the', '[', 'fire', 'department', ']', '!', '!', '!'], ['I', 'need', 'help', 'of', 'the', '[', 'fire', 'brigade', ']', 'for', 'the', 'use', 'of', 'fire', 'hydrant'], ['The', 'house', 'is', 'burned', ',', 'I', 'have', 'to', 'phone', 'the', '[', 'fire', 'department', ']'], ['A', 'fire', 'lighter', 'has', 'exploded', 'and', 'the', 'room', 'has', 'burned', ',', 'I', 'need', 'help', 'from', 'the', '[', 'fire', 'department', ']'], ['I', 'have', 'to', 'call', 'the', 'next', '[', 'fire', 'protection', ']', 'district', ',', 'please'], ['I', 'need', 'help', 'of', 'the', '[', 'fire', 'authority', ']', ',', 'please'], ['I', 'need', 'to', 'call', 'the', '[', 'fire', 'and', 'rescue', 'service', ']', ',', 'please'], ['Let', \"'s\", 'call', 'the', '[', 'fire', 'station', ']', ',', 'please'], ['Let', \"'s\", 'call', 'volunteer', '[', 'firefighters', ']', ',', 'we', 'need', 'an', 'urgent', 'help', '!', '!', '!'], ['We', 'need', 'help', ',', 'I', 'have', 'fire', 'in', 'my', 'house', ',', 'I', 'need', 'to', 'contact', 'the', '[', 'fire', 'brigade', ']'], ['My', 'house', 'is', 'burning', ',', 'please', 'I', 'need', 'to', 'contact', 'the', '[', 'firefighters', ']'], ['Please', 'I', 'need', 'to', 'contact', 'the', '[', 'fire', 'and', 'rescue', 'service', ']'], ['Neighbour', \"'s\", 'house', 'is', 'burning', ',', 'I', 'need', 'to', 'contact', '[', 'fire', 'department', ']'], ['I', 'have', 'to', 'call', 'the', '[', 'fireman', ']'], ['Please', 'let', \"'s\", 'contact', 'the', '[', 'firefighters', 'department', ']'], ['We', 'need', 'the', 'service', 'of', 'the', '[', 'firefighters', ']', 'here'], ['The', 'fire', 'alarm', 'is', 'not', 'working', 'let', \"'s\", 'contact', 'the', '[', 'firefighters', ']'], ['Please', 'I', 'have', 'to', 'call', 'the', '[', 'fire', 'patrol', ']', 'immediately'], ['I', 'need', 'to', 'phone', 'the', '[', 'firefighters', ']'], ['I', 'have', 'to', 'phone', 'the', '[', 'firefighters', 'station', ']'], ['We', 'can', 'not', 'stop', 'the', 'fire', ',', 'we', 'need', 'to', 'call', 'the', '[', 'fire', 'brigade', ']'], ['Fire', 'is', 'everywhere', ',', 'I', 'have', 'to', 'call', 'the', '[', 'fire', 'department', ']'], ['Fire', 'is', 'unstoppable', ',', 'I', 'have', 'to', 'call', 'the', 'close', '[', 'fire', 'station', ']'], ['Fire', 'is', 'developing', 'very', 'fast', ',', 'I', 'have', 'to', 'call', '[', 'firemen', ']'], ['We', 'have', 'emergency', 'at', 'house', ',', 'it', 'burning', ',', 'I', 'have', 'to', 'contact', 'the', '[', 'fire', 'protection', ']'], ['I', 'am', 'in', 'an', 'earthquake'], ['objects', 'are', 'falling'], ['ground', 'is', 'shaking'], ['Everything', 'is', 'shaking'], ['Ground', 'is', 'moving'], ['The', 'ground', 'is', 'developing', 'cracks'], ['ground', 'is', 'rupturing'], ['Home', 'is', 'damaged'], ['My', 'bed', 'is', 'shaking'], ['The', 'buildings', 'are', 'swinging'], ['Lots', 'of', 'water', 'around', 'me'], ['neighbourhood', 'is', 'flooded'], ['roads', 'submerged', 'under', 'water'], ['house', 'is', 'submerged', 'under', 'water'], ['water', 'all', 'around', 'me'], ['The', 'lanes', 'are', 'choked', 'with', 'water'], ['People', 'are', 'drowning', 'outside'], ['heavy', 'rainfall', 'damaged', 'houses'], ['lots', 'of', 'standstill', 'water'], ['water', 'filling', 'in', 'room']]\n"
     ]
    }
   ],
   "source": [
    "print(docs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf80a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Fire', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Earthquake', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood', 'Flood']\n"
     ]
    }
   ],
   "source": [
    "print(docs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a0196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'fir', 'has', 'spread', 'in', 'the', 'room', ',', 'i', 'hav', 'to', 'cal', 'the', '[', 'firefight', ']', ',', 'it', \"'s\", 'urg', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "wrds = [stemmer.stem(w) for w in docs_x[13]]\n",
    "print(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172ca0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))] # intialise the a list out_empty with 0's with len = length of labels\n",
    "\n",
    "for x, doc in enumerate(docs_x): # creates tuples of docs_x's index and values such that the index of the docs_x elements are stores in x and the element values are stored in the variable doc\n",
    "    \n",
    "\tbag = []\n",
    "    \n",
    "\twrds = [stemmer.stem(w) for w in doc]\n",
    "\n",
    "\tfor w in words:\n",
    "\t\tif w in wrds:\n",
    "\t\t\tbag.append(1)\n",
    "\t\telse:\n",
    "\t\t\tbag.append(0)\n",
    "            \n",
    "\toutput_row = out_empty[:]\n",
    "\toutput_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "\ttraining.append(bag)\n",
    "\toutput.append(output_row)\n",
    "\n",
    "training = np.array(training)\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37d6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(training)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a9f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shivansh uppal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# neural network model\n",
    "tf.compat.v1.reset_default_graph() # creates a fresh new empty graph by clearing the nodes and operations of any previous computation\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])]) # None specifies that the input layer can accept a variable number of samples., no of neurons in input layer= 32\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\") #  no of neurons = 3\n",
    "net = tflearn.regression(net)\n",
    "# net = tflearn.softmax_categorical_crossentropy(net,output)\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27206012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8999  | time: 0.031s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 1.0000 -- iter: 64/67\n",
      "Training Step: 9000  | time: 0.033s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 1.0000 -- iter: 67/67\n",
      "--\n",
      "INFO:tensorflow:c:\\programming languages\\CYBERCUP\\CyberCup\\manya\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:c:\\programming languages\\CYBERCUP\\CyberCup\\manya\\model.tflearn.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:c:\\programming languages\\CYBERCUP\\CyberCup\\manya\\model.tflearn.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:c:\\programming languages\\CYBERCUP\\CyberCup\\manya\\model.tflearn.meta\n",
      "INFO:tensorflow:200\n"
     ]
    }
   ],
   "source": [
    "# neural network training\n",
    "try:\n",
    "\tmodel.load(\"model.tflearn\")\n",
    "except:\n",
    "    model = tflearn.DNN(net)\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(\"model.tflearn\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d5a4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "\tbag = [0 for _ in range(len(words))]\n",
    "\ts_words = nltk.word_tokenize(s)\n",
    "\ts_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "\tfor se in s_words:\n",
    "\t\tfor i, w in enumerate(words):\n",
    "\t\t\tif w == se:\n",
    "\t\t\t\tbag[i] = 1\n",
    "\n",
    "\treturn np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "271d6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat interface\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import datetime\n",
    "\n",
    "engine = pyttsx3.init('sapi5') #sapi5 is microsoft speech api\n",
    "voices = engine.getProperty('voices') #main program\n",
    "engine.setProperty('voice',voices[0].id)\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def chat():\n",
    "    print(\"Start Talking with the Bot (say quit to stop!)\")\n",
    "    while True:\n",
    "        r=sr.Recognizer()\n",
    "        inp=[]\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Listening...\")\n",
    "            r.pause_threshold = 0.5\n",
    "            audio = r.listen(source)\n",
    "        try:\n",
    "            print(\"Recognizing...\")\n",
    "            inp = r.recognize_google(audio, language='en-in')\n",
    "            print(f\"You: {inp}\\n\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Say that again please...\")\n",
    "        \n",
    "        if inp==\"quit\":\n",
    "            return \"None\"\n",
    "            \n",
    "        \n",
    "        results = model.predict([bag_of_words(inp, words)])[0]\n",
    "        results_index=np.argmax(results)\n",
    "        tag=labels[results_index]\n",
    "        \n",
    "        if results[results_index] > 0.5:\n",
    "            for tg in dataset[\"data\"]:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "                    speak(random.choice(responses))\n",
    "                    print(random.choice(responses))\n",
    "                    print(\"\\n\")\n",
    "    \n",
    "\t\t#inp = input(\"You: \")\n",
    "\t\t#if inp.lower() == \"quit\":\n",
    "\t\t#\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efdcada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Talking with the Bot (say quit to stop!)\n",
      "Listening...\n",
      "Recognizing...\n",
      "You: fire\n",
      "\n",
      "Please consider the following measures- \n",
      " 1. Stay calm and do not panic \n",
      " 2. Sound the fire alarm and shout to alert others in the house \n",
      " 3. Call the local fire department immediately by dialing 101 or the emergency number in your area. Provide them with your address and details of the fire. \n",
      " 4. Close all doors and windows to contain the fire and prevent it from spreading. \n",
      " 5. Evacuate the house immediately and gather at a safe location outside.\n",
      "\n",
      "\n",
      "\n",
      "Listening...\n",
      "Recognizing...\n",
      "You: super lunch\n",
      "\n",
      "Please consider the following measures- \n",
      " 1. Stay calm and do not panic \n",
      " 2. Sound the fire alarm and shout to alert others in the house \n",
      " 3. Call the local fire department immediately by dialing 101 or the emergency number in your area. Provide them with your address and details of the fire. \n",
      " 4. Close all doors and windows to contain the fire and prevent it from spreading. \n",
      " 5. Evacuate the house immediately and gather at a safe location outside.\n",
      "\n",
      "\n",
      "\n",
      "Listening...\n",
      "Recognizing...\n",
      "You: bus vahan se main nikala aur FIR Maine unko bola ki bhai aaj water water everywhere\n",
      "\n",
      "Please consider the following measures- \n",
      " 1. Stay calm and do not panic \n",
      " 2. Sound the fire alarm and shout to alert others in the house \n",
      " 3. Call the local fire department immediately by dialing 101 or the emergency number in your area. Provide them with your address and details of the fire. \n",
      " 4. Close all doors and windows to contain the fire and prevent it from spreading. \n",
      " 5. Evacuate the house immediately and gather at a safe location outside.\n",
      "\n",
      "\n",
      "\n",
      "Listening...\n",
      "Recognizing...\n",
      "You: quit quit\n",
      "\n",
      "Please consider the following measures- \n",
      " 1. Stay calm and do not panic \n",
      " 2. Sound the fire alarm and shout to alert others in the house \n",
      " 3. Call the local fire department immediately by dialing 101 or the emergency number in your area. Provide them with your address and details of the fire. \n",
      " 4. Close all doors and windows to contain the fire and prevent it from spreading. \n",
      " 5. Evacuate the house immediately and gather at a safe location outside.\n",
      "\n",
      "\n",
      "\n",
      "Listening...\n",
      "Recognizing...\n",
      "You: quit\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start chatting\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1411703",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c4598cb0e8224ee4992ef7f7aa2c97883472946fa3b7b41abaa0dd95d9de624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
